import os
import getpass
import warnings
from langchain.vectorstores import FAISS
from langchain_upstage import UpstageEmbeddings, ChatUpstage
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain.document_loaders import WebBaseLoader
from datetime import datetime
import uuid
import re
import streamlit as st
import tkinter as tk
from audio_recoder import AudioRecorder
import requests
import spacy
from sklearn.metrics.pairwise import cosine_similarity
from streamlit.components.v1 import html
warnings.filterwarnings("ignore")

os.environ["UPSTAGE_API_KEY"] = "Your_Upstage_KEY"
if "UPSTAGE_API_KEY" not in os.environ or not os.environ["UPSTAGE_API_KEY"]:
    os.environ["UPSTAGE_API_KEY"] = getpass.getpass("Enter your UPSTAGE API KEY: ")
    print("API key has been set successfully.")
else:
    print("API key is already set.")


def call_upstage_solar_api(prompt):
    api_url = "https://api.upstage.ai/v1/solar/chat/completions"
    api_key = os.getenv("UPSTAGE_API_KEY")
    if not api_key:
        raise ValueError("ì—…ìŠ¤í…Œì´ì§€ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    data = {
        "model": "solar-1-mini-chat",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.8,
        "top_p": 0.85,
        "max_tokens": 500
    }

    try:
        response = requests.post(api_url, headers=headers, json=data)
        if response.status_code == 200:
            print("ì—…ìŠ¤í…Œì´ì§€ Solar API ì—°ê²° ì„±ê³µ!")
            response_data = response.json()
            answer = response_data["choices"][0]["message"]["content"]
            return answer
        else:
            raise Exception(f"ì—…ìŠ¤í…Œì´ì§€ Solar API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}, {response.text}")

    except Exception as e:
        print(f"ì˜ˆì™¸ ë°œìƒ: {e}")
        return None

# ë°ì´í„°ë¡œë“œ
embeddings = UpstageEmbeddings(model='embedding-query')
vectorstore = FAISS.load_local("C:\Python\Fast-Doctor\health_care", embeddings, allow_dangerous_deserialization=True)
class ConversationHistory:
    def __init__(self, embeddings, index_path="history_vectorstore.index"):
        self.history = {}
        self.embeddings = embeddings
        self.history_vectorstore = None
        self.index_path = index_path
        self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)

    def add_to_history(self, session_id, user_input, bot_response):
        if session_id not in self.history:
            self.history[session_id] = []

        self.history[session_id].append({'user_input': user_input, 'bot_response': bot_response})
        self.save_to_faiss(user_input, bot_response, session_id)

    def get_history(self, session_id):
        history_entries = self.history.get(session_id, [])
        return " ".join([f"User: {entry['user_input']} Bot: {entry['bot_response']}" for entry in history_entries])

    def reset_history(self, session_id):
        if session_id in self.history:
            del self.history[session_id]

        if self.history_vectorstore is not None:
            self.history_vectorstore.reset()
            self.history_vectorstore = FAISS.from_documents([], self.embeddings)
        print("ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def save_to_faiss(self, user_input, bot_response, session_id):
        combined_text = f"User: {user_input} Bot: {bot_response}"
        history_docs = [Document(page_content=combined_text)]
        history_splits = self.text_splitter.split_documents(history_docs)

        if self.history_vectorstore is None:
            self.history_vectorstore = FAISS.from_documents(history_splits, self.embeddings)

        metadata = [{'type': 'conversation', 'session_id': session_id} for _ in history_splits]
        texts = [split.page_content for split in history_splits]
        self.history_vectorstore.add_texts(texts=texts, metadatas=metadata)
        self.history_vectorstore.save_local(self.index_path)
        print("ëŒ€í™” ê¸°ë¡ì´ FAISSì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def list_sessions(self):
        return list(self.history.keys())

    def _generate_session_id(self):
        return f"session_{datetime.now().strftime('%Y%m%d%H%M%S')}_{uuid.uuid4().hex[:6]}"

class SessionManager:
    def __init__(self, conversation_history):
        self.conversation_history = conversation_history
        self.sessions = {}

    def create_session(self):
        session_id = self.conversation_history._generate_session_id()
        self.sessions[session_id] = {'conversation': []}
        return session_id

    def get_session(self, session_id):
        return self.sessions.get(session_id, None)

    def save_message(self, session_id, user_input, bot_response=None):
        self.conversation_history.add_to_history(session_id, user_input, bot_response)

    def get_conversation(self, session_id):
        return self.conversation_history.get_history(session_id)

    def get_all_sessions(self):
        return list(self.sessions.keys())


class ChatUI:
    def __init__(self, root, session_manager):
        self.root = root
        self.session_manager = session_manager
        self.current_session_id = None
        self.create_ui()

    def create_ui(self):
        self.text_box = tk.Text(self.root, height=15, width=50)
        self.text_box.pack(padx=10, pady=10)
        self.input_box = tk.Entry(self.root, width=40)
        self.input_box.pack(pady=10)
        self.send_button = tk.Button(self.root, text="Send", command=self.send_message)
        self.send_button.pack(pady=10)
        self.new_session_button = tk.Button(self.root, text="New Session", command=self.new_session)
        self.new_session_button.pack(pady=10)
        self.session_list_box = tk.Listbox(self.root, height=5, width=50)
        self.session_list_box.pack(pady=10)
        self.session_list_box.bind("<ButtonRelease-1>", self.select_session)

    def send_message(self):
        message = self.input_box.get()
        if message:
            bot_response = "This is a bot response."
            if self.current_session_id:
                self.session_manager.save_message(self.current_session_id, message, None)
                self.update_conversation()
                self.session_manager.save_message(self.current_session_id, message, bot_response)
                self.update_conversation()

    def new_session(self):
        session_id = self.session_manager.create_session()
        self.current_session_id = session_id
        self.session_list_box.insert(tk.END, session_id)
        self.text_box.delete(1.0, tk.END)

    def select_session(self, event):
        selected_session = self.session_list_box.curselection()
        if selected_session:
            session_id = self.session_list_box.get(selected_session)
            self.current_session_id = session_id
            conversation = self.session_manager.get_conversation(session_id)
            self.text_box.delete(1.0, tk.END)
            if conversation:
                self.text_box.insert(tk.END, "\n".join(conversation))

    def update_conversation(self):
        if self.current_session_id:
            conversation = self.session_manager.get_conversation(self.current_session_id)
            if conversation:
                self.text_box.delete(1.0, tk.END)
                self.text_box.insert(tk.END, "\n".join(conversation))


os.environ["USER_AGENT"] = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
class ExternalDocumentManager:
    def __init__(self):
        self.external_docs = []
        self.external_vectorstore = None
        self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)

    def fetch_documents_from_url(self, url):
        url_pattern = re.compile(r'https?://[^\s]+')
        if not url_pattern.fullmatch(url):
            print("ìœ íš¨í•˜ì§€ ì•Šì€ URLì…ë‹ˆë‹¤.")
            return

        try:
            headers = {'User-Agent': os.environ["USER_AGENT"]}
            web_loader = WebBaseLoader(url, headers=headers)
            web_docs = web_loader.load()

            if web_docs:
                self.add_external_documents(web_docs)
                print("ì›¹ì‚¬ì´íŠ¸ì—ì„œ ë¬¸ì„œë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
            else:
                print("ì›¹ì‚¬ì´íŠ¸ì—ì„œ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except requests.exceptions.RequestException as e:
            print(f"ì›¹ì‚¬ì´íŠ¸ì—ì„œ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        except Exception as e:
            print(f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    def add_external_documents(self, documents):
        doc_splits = self.text_splitter.split_documents(documents)
        self.external_docs.extend(doc_splits)
        self.external_vectorstore = FAISS.from_documents(doc_splits, embeddings)
        print(f"{len(doc_splits)}ê°œì˜ ë¬¸ì„œê°€ ì™¸ë¶€ ë¬¸ì„œë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")



nlp = spacy.load("en_core_web_sm")

def retrieve_documents_with_similarity(query, top_k=1):
    query_vector = embeddings.embed_query(query)
    retriever = vectorstore.as_retriever(search_type="mmr", search_kwargs={'k': top_k})
    result_docs = retriever.invoke(query)
    results_with_similarity = []

    for doc in result_docs:
        doc_vector = embeddings.embed_query(doc.page_content)
        similarity = cosine_similarity([query_vector], [doc_vector])[0][0]
        results_with_similarity.append((doc, similarity))
        print(f"ë¬¸ì„œ: {doc.page_content[:150]}... ìœ ì‚¬ë„: {similarity:.4f}")

    results_with_similarity = sorted(results_with_similarity, key=lambda x: x[1], reverse=True)
    return results_with_similarity


def contextualized_retrieval_with_similarity(user_question, conversation_history, session_id, external_manager=None,
                                             top_k=1):
    context = conversation_history.get_history(session_id)
    if conversation_history.history_vectorstore:
        relevant_docs = conversation_history.history_vectorstore.similarity_search(user_question, k=top_k)
        if relevant_docs:
            context += "\n\n" + "\n".join([highlight_text(doc.page_content, user_question) for doc in relevant_docs])

    enhanced_question = f"{context} {user_question}"

    if external_manager and external_manager.external_docs:
        external_docs_content = "\n\n".join(
            [highlight_text(doc.page_content, user_question) for doc in external_manager.external_docs])
        enhanced_question = f"{enhanced_question}\n\n{external_docs_content}"
    main_results_with_similarity = retrieve_documents_with_similarity(enhanced_question, top_k)
    return main_results_with_similarity


def generate_prompt_with_similarity(user_input, conversation_history, session_id, external_manager):
    results_with_similarity = contextualized_retrieval_with_similarity(
        user_input, conversation_history, session_id, external_manager, top_k=3
    )
    print("\n--- ìœ ì‚¬ë„---")
    for doc, similarity in results_with_similarity:
        print(f"ìœ ì‚¬ë„: {similarity:.4f}")
    print("-------------------")

    context = "\n\n".join(
        [f"{doc.page_content} (ìœ ì‚¬ë„: {similarity:.4f})" for doc, similarity in results_with_similarity])
    prompts = ChatPromptTemplate.from_messages(
        [
            ("system", """
                ë‹¹ì‹ ì€ ì˜í•™ ì „ë¬¸ ì§€ì‹ì„ ê°–ì¶˜ AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
                ì‚¬ìš©ìê°€ ë¬»ëŠ” ì§ˆë¬¸ì— ëŒ€í•´ ê´€ë ¨ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
                ë§Œì•½ ë‹µì„ ëª¨ë¥¸ë‹¤ë©´ ëª¨ë¥¸ë‹¤ê³  ì •í™•íˆ ë§í•´ì£¼ì‹œê³  ê°€ëŠ¥í•˜ë‹¤ë©´ ì—¬ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ë‚˜ í•´ê²°ì±…ì„ ê³ ë ¤í•´ ë‹µë³€ì„ ë‹¤ì–‘í•˜ê²Œ ì œê³µí•´ì£¼ì„¸ìš”.
                ëŒ€í™”ê°€ ì§„í–‰ë˜ëŠ” ë™ì•ˆ ë™ì¼í•œ ë‹µë³€ì€ í”¼í•´ì£¼ì‹œê³  ë‹µë³€ì€ 3ë¬¸ì¥ ë‚´ì™¸ë¡œ ê°„ì¶”ë ¤ ì£¼ì‹œê¸¸ ë°”ëë‹ˆë‹¤.
                ë˜í•œ ê°•ì¡°í•  ë¶€ë¶„ì´ ìˆë‹¤ë©´ êµµì€ ê¸€ìë¡œ ê°•ì¡°í•´ì£¼ì„¸ìš”.
                ---
                CONTEXT:
                {context}
            """),
            ("human", "{input}")
        ]
    )
    return prompts, context


def generate_answer_with_similarity(user_input, conversation_history, session_id, external_manager=None):
    try:
        prompts, context = generate_prompt_with_similarity(user_input, conversation_history, session_id,
                                                           external_manager)
        llm = ChatUpstage(model='solar-pro')
        chain = prompts | llm | StrOutputParser()
        response = chain.invoke({"input": user_input, "context": context})
        highlighted_answer = highlight_text(response, user_input)
        return highlighted_answer
    except Exception as e:
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


def extract_important_terms_from_query(query):
    doc = nlp(query)
    important_terms = [token.text for token in doc if token.pos_ in ["NOUN", "VERB", "ADJ", "NUM"]]
    return important_terms

def highlight_text(text, query):
    important_terms = extract_important_terms_from_query(query)
    if not important_terms:
        return text

    highlighted_text = text
    for term in important_terms:
        highlighted_text = re.sub(rf"({re.escape(term)})", r'**\1**', highlighted_text, flags=re.IGNORECASE)
    return highlighted_text

def chat_interface():
    st.set_page_config(page_title="AI ì±—ë´‡", page_icon=":robot_face:")
    st.title("ğŸ¤– Dr.Fast")
    st.markdown("""
            ğŸ”¹ ì•ˆë…•í•˜ì„¸ìš”. Dr.Fastì…ë‹ˆë‹¤. ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”.<br>
            ğŸ”¹ ì €ë¥¼ í†µí•´ ë¹ ë¥¸ ì˜ë£Œ ë„ì›€ì„ ë°›ìœ¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """,
            unsafe_allow_html=True)
    st.markdown("""
        <style>
            .e1obcldf2 {
                border-radius: 10px;
                background-color: #F0F2F6;
                border: 1px solid transparent;
            }
            .e1obcldf2:hover {      
                border: 1px solid #FF4B4B;         
            }
            .stHorizontalBlock {
                position: fixed;
                bottom: 0;
                padding-bottom: 30px; /* í•˜ë‹¨ */
                padding-top: 20px; /* í•˜ë‹¨ */
                z-index: 1000; /* ìš°ì„  ìˆœìœ„ */
                width: 100%;
                max-width: 704px;
                background-color: white;
            }
            .stMainBlockContainer {
                overflow-y: auto
            }
            
            [data-testid="stSidebarNav"] a[href*="home"] {
            pointer-events: none; /* í´ë¦­ ë°©ì§€ */
            opacity: 0.8; 
            text-decoration: none; 
            background-color: transparent;
            }        
        </style> 
    """, unsafe_allow_html=True)
    if "conversation_history" not in st.session_state:
        st.session_state.conversation_history = ConversationHistory(embeddings)
    if "session_manager" not in st.session_state:
        st.session_state.session_manager = SessionManager(st.session_state.conversation_history)
    if "external_manager" not in st.session_state:
        st.session_state.external_manager = ExternalDocumentManager()

    conversation_history = st.session_state.conversation_history
    session_manager = st.session_state.session_manager
    external_manager = st.session_state.external_manager
    session_id = "Chatbot1"

    if f"{session_id}_messages" not in st.session_state:
        st.session_state[f"{session_id}_messages"] = []

    conversation = st.session_state[f"{session_id}_messages"]

    for message in conversation:
        if isinstance(message, dict):
            st.chat_message(message["role"]).markdown(message["content"])
        else:
            st.chat_message("assistant").markdown(message)

    # ë ˆì´ì•„ì›ƒ ì¡°ì •
    col1, col2 = st.columns([1, 15])  # ì±„íŒ… ì…ë ¥ê³¼ ìŒì„± ë…¹ìŒì„ ë‘ ì—´ë¡œ ë°°ì¹˜

    with col1:
        # ì˜¤ë””ì˜¤ ë ˆì½”ë”
        recorder = AudioRecorder(silence_timeout=2)
        user_input_audio = recorder.run()

    with col2:
        # ì‚¬ìš©ì ì…ë ¥ í•„ë“œ
        user_input_text = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")

    #user_input_text = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”!")
    # recorder = AudioRecorder(silence_timeout=2)
    # user_input_audio = recorder.run()

    if user_input_text:
        user_input = user_input_text
    elif user_input_audio:
        user_input = user_input_audio
        print(user_input_audio)
    else:
        user_input = None

    if user_input:
        user_message = {"role": "user", "content": user_input}
        st.session_state[f"{session_id}_messages"].append(user_message)
        st.chat_message(user_message["role"]).markdown(user_message["content"])

        response = generate_answer_with_similarity(
            user_input,
            conversation_history,
            session_id,
            external_manager if external_manager.external_docs else None
        )

        assistant_message = {"role": "assistant", "content": response}
        st.session_state[f"{session_id}_messages"].append(assistant_message)
        st.chat_message(assistant_message["role"]).markdown(assistant_message["content"])
        conversation_history.add_to_history(session_id, user_input, response)
        session_manager.save_message(session_id, assistant_message)

if __name__ == "__main__":
    chat_interface()
